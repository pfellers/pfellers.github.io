---
title: "Research Highlights"
---
I utilize creative applications of statistical and research methods to examine current statistical practice in order to advance the effective and appropriate use of data anlaytic techniques. My research portfolio includes statistical methodology projects and scholarship on the teaching and learning of statistics. 

In addition the research highlighted here, I am invested in mentoring undergraduate researchers. Showcasing this work deserved a separate page, see _Undergraduate Research_ in the drop-down for Research. The two primary areas I have mentored undergraduate projects on are survey analysis and text analysis.  

## Scholarship on the Teaching and Learning of Statistics
It is essential to continually think about what and how we teach statistics, specifically at the undergradaute level. The landscape of statistics and statistics education is continually being influcenced by advancements in technology and data capabilites. How do we ensure we are providing meaningful experiences that provide foundational knowledge in the discipline yet prepares students for consuming and/or producing quality statistical informaiton? 

Collaborating with Shonda Kuiper we developed learning activities and presented stratgies for incorporating an introduction to survey data, specifically weighted survey data, into the undergraduate classroom. This project aims to address the disparity between classroom experiences with survey data and the reality of how complex survey data often is in reality. 

Other presentations and collaborations related to the scholarship of teaching and learning in statistics address the role of statistical consulting and the dissemination of class activities and projects. 

#### Papers and Presentations:
* Fellers, Pamela S., Kuiper, S. "Introducing Undergraduates to Concepts of Survey Data Analysis." Journal of Statistics Education 28, no. 1 (2020): 18-24.
* Fellers, P. “Illustrative Examples to Promote and Encourage the Appropriate use of Survey Data”, Electronic Conference on Teaching Statistics, May 19, 2020, https://www.causeweb.org/cause/ecots/ecots20/posters/2-10
* Fellers, P., Kuiper, S., Barnard-Mayers, R., and Yndestad, K. “Beyond the SRS: A Weighted Survey Data Example”, Electronic Conference on Teaching Statistics, May 19, 2016; https://www.causeweb.org/cause/ecots/ecots16/posters/d/8
* Fellers, P. and Schwab, A. “Statistical Consulting: Making Connections Across the Curriculum,” Refereed Presentation (approx. 50% acceptance), United States Conference on Teaching Statistics, May 29, 2015; State College, PA.
* Fellers, P., “The bubble Project,” Invited Webinar, Consortium for the Advancement of Undergraduate Statistics Education (CAUSE), April 26, 2016; https://www.causeweb.org/cause/webinar/activity/2016-04

## Evaluation in Education (methodological)
With the growing desire for accountability in education advanced statistical modeling techniques are being utilized to measure and quantify impact of educational entities on student achievement. It is essential to carefully consider the nuances of the methods and data when interepreting results. Particularly when wanting to utilize results for high-stakes decisions or policies. Along with colleagues, we examined Value-Added models and how they may be utilized in the educational setting in inforamtive ways. 

 * My dissertation research focused on utilizing simulation studies to understand model beahvior when utilized with less than ideal data. Specifically, I examined non-random assignment of students to classrooms, assessment ceiling effects, and complex student growth trajectories.
 * Working as a collaborator with W. Stroup and J. Green we presented and examined methodology for quantifying professional development program effects in the education setting. Our methodology examines impact from a distributional perspective (random effect) rather than a single, constant fixed effect.

#### Papers and Presenations:
* Green, J., Stroup, W., and Fellers, P. "Defining Program Effects: A Distribution-Based Perspective." Statistics and Public Policy 4.1 (2017): 1-10.
* Green, J., Stroup, W., Fellers, P., and Broatch, J. “Using Value-Added Models to Assess Teacher Professional Development Programs,” Referred Presentation (J. Green presenter), National Council on Measurement in Education, April 1, 2015, Chicago, IL.
* Fellers, P., Green, J., Lukin, L., Smith, W., Stroup, W., and Sutton, J. “An Investigation of the Behavior of Value-Added Models for Estimating MSP Impact,” Refereed Presentation, NSF Math Science Partnership Learning Network Conference, February 11, 2013; Washington D.C.
* Green, J., Stroup, W., and Fellers, P., “Data Connections: Methodology for Developing Student Achievement Trajectories to Estimate Teaching Effectiveness,” Refereed Presentation, NSF Math Science Partnership Learning Network Conference, January 23, 2012; Washington D.C.
* Fellers, P., “Impact of Real-Data Characteristics on Estimates from VAMs: Nonrandomization, Assessment Ceiling Effects, and Student Growth Trajectories,” Topic Contributed Presentation, Joint Statistical Meetings, August 8, 2014; Boston, MA
* Fellers, P., Green, J., and Stroup, W. “Investigation of the Impact of Non-randomization and Ceiling Effects on Estimates of Program Effects from Value-Added Models,” Paper Presentation, Joint Statistical Meetings, August 5, 2013; Montréal, Québec, Canada.
* Fellers. P. “Binning by Quantile Applied to Value-Added Models in Education,” Paper Presentation, Joint Statistical Meetings, July 29, 2012; San Diego, CA
* Fellers P. “Binning by Quantile Applied to Value-Added Models in Education,” Poster Presentation, Graduate Student Poster Session, UNL Research Fair, April 4, 2012; Lincoln, NE
